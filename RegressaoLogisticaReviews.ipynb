{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from translation import baidu, google, youdao, iciba, bing\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "import time\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "from scipy.stats import uniform, levy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import calendar\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from random import randint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from unidecode import unidecode\n",
    "import json\n",
    "import gc\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from dateutil import parser\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo de regressão logística\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to make a cleaning procedure in texts. Enter, for example df['text'], and get a list of clean text\n",
    "def cleaning(dfcolumn, stopwords_language):\n",
    "    \n",
    "    text_list_zero = dfcolumn.tolist()\n",
    "    \n",
    "    print ' '\n",
    "    print ' '\n",
    "    print 'eliminating excess of blank space: '\n",
    "    print ' '\n",
    "    \n",
    "    text_list_one = []\n",
    "    time1 = time.time()\n",
    "    for k in xrange(0, len(text_list_zero)): #tamanho da coluna \n",
    "        test = k % 100\n",
    "        if test == 0:\n",
    "            print k\n",
    "            \n",
    "        text_list_one.append( ' '.join(text_list_zero[k].split()) )\n",
    "        \n",
    "    print 'step time: ', time.time() - time1\n",
    "    print 'partial total time: ', time.time() - time1    \n",
    "    print ' '\n",
    "    print ' '\n",
    "\n",
    "    print ' '\n",
    "    print ' '\n",
    "    print 'eliminating urls: '\n",
    "    print ' '\n",
    "    \n",
    "    text_list_2 = []\n",
    "    time2 = time.time()\n",
    "    for k in xrange(0, len(text_list_one)):\n",
    "        test = k % 100\n",
    "        if test == 0:\n",
    "            print k\n",
    "        text = text_list_one[k]\n",
    "        text_clean = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', text)\n",
    "        text_list_2.append(text_clean) #remove a url do texto do tweet\n",
    "    print 'step time: ', time.time() - time2\n",
    "    print 'partial total time: ', time.time() - time1\n",
    "    print ' '\n",
    "    print ' '\n",
    "    \n",
    "    #text_list_2 é a lista com os tweets já sem a url\n",
    "    # strings to erase:\n",
    "    \n",
    "    toerase =  ['gostei de um video @youtube',\\\n",
    "                'www.','.com','.',',','!','?',';','@','...','/','(',')','\"',':',\\\n",
    "               '=','#','-','&','|','%','*','\"',\"'s\",'[', ']',\" ' \",\"$\", '\\n', '>', '<', '+',\\\n",
    "               'rss', '{', '}',\n",
    "               'website', 'https:','https', 'http', 'http:', \"'\", 'feedly', 'sign', 'comment', \\\n",
    "               'clique aqui', 'click here', 'comments']\n",
    "\n",
    "    \n",
    "    print ' '\n",
    "    print ' '\n",
    "    print 'eliminating more strings... '\n",
    "    print ' '    \n",
    "    \n",
    "    \n",
    "    text_list_3 = []\n",
    "    time3 = time.time()\n",
    "    for k in xrange(0, len(text_list_2)):\n",
    "        test = k % 100\n",
    "        if test == 0:\n",
    "            print k        \n",
    "        #text_zero = unidecode(text_list_2[k].decode('utf-8')).lower() #codifica a lista dos tweets em utf8\n",
    "        text_zero = unidecode((text_list_2[k].encode('utf-8')).decode('utf-8')).lower()\n",
    "        \n",
    "        vector_text = []\n",
    "        temp = text_zero #agora temp é a lista dos tweets em utf8\n",
    "        for j in xrange(0, len(toerase)):    \n",
    "            temp2 = temp.replace(toerase[j],' ') #substitui os caracteres to erase por espaços na lista já sem a url, \n",
    "            #remove um caracter indesejado por iteração de todos os tweets\n",
    "            #então na última iteração de j, todos os caracteres já estarão removidos\n",
    "            #por isso que pega o último elemento com índice -1 do vetor temp2\n",
    "            \n",
    "            vector_text.append(temp2) #vector_text já está ok \n",
    "            temp = vector_text[j] #agora temp recebe cada tweet \n",
    "        text_one = vector_text[-1].strip()    \n",
    "        tokens = [w for w in word_tokenize(text_one) if not w in stopwords.words(stopwords_language)]\n",
    "        #tokeniza cada tweet , então w é cada tweet tokenizado. Remove as stopwords dos tokens\n",
    "        #tokens contém os tweets já tokenizados e sem as stopwords \n",
    "       \n",
    "        text_final = ' '.join(tokens)\n",
    "        text_list_3.append(text_final)\n",
    "    print 'step time: ', time.time() - time3\n",
    "    print 'Total time: ', time.time() - time1\n",
    "    print ' '\n",
    "    print ' '\n",
    "    \n",
    "    return text_list_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder =  str(os.getcwd()+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframes\n",
    "df_temp_pos = pd.read_csv('data_pos_final.csv', sep = '\\t', encoding = 'utf-8')\n",
    "df_temp_neg = pd.read_csv('data_neg_final.csv', sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatena os dataframes com as duas classes\n",
    "df_conc = [df_temp_pos, df_temp_neg]\n",
    "df_conc2 = pd.concat(df_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mistura as duas classes\n",
    "df_mix = df_conc2.sample(frac=1).reset_index(drop=True) #mix datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>traducao_pt</th>\n",
       "      <th>polaridade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>while this gentle and affecting melodrama will...</td>\n",
       "      <td>enquanto esse melodrama gentil e afetivo terá ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weirdly , broomfield has compelling new materi...</td>\n",
       "      <td>Estranhamente, broomfield tem material novo e ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flamboyant in some movies and artfully restrai...</td>\n",
       "      <td>O nicholson de 65 anos poderia estar olhando p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a prison comedy that never really busts out of...</td>\n",
       "      <td>uma comédia de prisão que nunca sai da sua peq...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  while this gentle and affecting melodrama will...   \n",
       "1  weirdly , broomfield has compelling new materi...   \n",
       "2  flamboyant in some movies and artfully restrai...   \n",
       "3  a prison comedy that never really busts out of...   \n",
       "\n",
       "                                         traducao_pt  polaridade  \n",
       "0  enquanto esse melodrama gentil e afetivo terá ...           1  \n",
       "1  Estranhamente, broomfield tem material novo e ...           0  \n",
       "2  O nicholson de 65 anos poderia estar olhando p...           1  \n",
       "3  uma comédia de prisão que nunca sai da sua peq...           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mix[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "eliminating excess of blank space: \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  0.0465948581696\n",
      "partial total time:  0.0468440055847\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "eliminating urls: \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  0.0299689769745\n",
      "partial total time:  0.0777449607849\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "eliminating more strings... \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  28.5784480572\n",
      "Total time:  28.6564669609\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#limpa as colunas do dataset\n",
    "df_mix['review'] = cleaning(df_mix['review'], 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "eliminating excess of blank space: \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  0.052188873291\n",
      "partial total time:  0.0522539615631\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "eliminating urls: \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  0.0327749252319\n",
      "partial total time:  0.0857028961182\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "eliminating more strings... \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  30.07020998\n",
      "Total time:  30.1560359001\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#limpa as colunas do dataset\n",
    "df_mix['traducao_pt'] = cleaning(df_mix['traducao_pt'], 'portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vetorização e conversão de variáveis\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "review = vectorizer.fit_transform(df_mix.review).toarray()\n",
    "traducao = vectorizer.fit_transform(df_mix.traducao_pt).toarray()\n",
    "polaridade = df_mix['polaridade'].as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide a base em treino e teste com 70% para treino e 30% para teste\n",
    "#database do review\n",
    "x_train_review, x_test_review, y_train_review, y_test_review = train_test_split(review, polaridade, test_size=0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide a base em treino e teste com 70% para treino e 30% para teste\n",
    "#database da traducao\n",
    "x_train_trans, x_test_trans, y_train_trans, y_test_trans = train_test_split(traducao, polaridade, test_size=0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review data\n",
    "#model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#training\n",
    "lr.fit(x_train_review, y_train_review)\n",
    "\n",
    "#testing\n",
    "y_predicted_review = lr.predict(x_test_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translated data\n",
    "#model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#training\n",
    "lr.fit(x_train_trans, y_train_trans)\n",
    "\n",
    "#testing\n",
    "y_predicted_trans = lr.predict(x_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426470588235294"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy review\n",
    "acc_score_review = accuracy_score(y_test_review, y_predicted_review)\n",
    "acc_score_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7327365728900256"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy translation\n",
    "acc_score_trans = accuracy_score(y_test_trans, y_predicted_trans)\n",
    "acc_score_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1160,  408],\n",
       "       [ 397, 1163]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix review\n",
    "#Thus in binary classification, the count of true negatives is C{0,0}, \n",
    "#false negatives is C{1,0}, true positives is C{1,1} and false positives is C{0,1}.\n",
    "\n",
    "cf_matrix_review = confusion_matrix(y_test_review, y_predicted_review)\n",
    "cf_matrix_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1142,  426],\n",
       "       [ 410, 1150]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix trans\n",
    "#Thus in binary classification, the count of true negatives is C{0,0}, \n",
    "#false negatives is C{1,0}, true positives is C{1,1} and false positives is C{0,1}.\n",
    "\n",
    "cf_matrix_trans = confusion_matrix(y_test_trans, y_predicted_trans)\n",
    "cf_matrix_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426468221015651"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1 score review\n",
    "f1_score_review = f1_score(y_test_review, y_predicted_review, average='macro')  \n",
    "f1_score_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7327348246991104"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1 score trans\n",
    "f1_score_trans = f1_score(y_test_trans, y_predicted_trans, average='macro')  \n",
    "f1_score_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426576431278713"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision score review\n",
    "#The precision is the ratio tp / (tp + fp)\n",
    "prec_score_review = precision_score(y_test_review, y_predicted_review, average='macro')  \n",
    "prec_score_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7327600868700612"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision score trans\n",
    "#The precision is the ratio tp / (tp + fp)\n",
    "prec_score_trans = precision_score(y_test_trans, y_predicted_trans, average='macro')  \n",
    "prec_score_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
