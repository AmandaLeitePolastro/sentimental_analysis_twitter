{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from translation import baidu, google, youdao, iciba, bing\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "import time\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "from scipy.stats import uniform, levy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import calendar\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "from random import randint\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from unidecode import unidecode\n",
    "import json\n",
    "import gc\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from dateutil import parser\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kognita/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion of probabilities to predictions in order\n",
    "#to calculate metrics \n",
    "def convertscore(x):\n",
    "    x.tolist()\n",
    "    for k in range(0, len(x)):\n",
    "        if (x[k] > 0.5):\n",
    "            x[k] = 1\n",
    "        else:\n",
    "            x[k] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to make a cleaning procedure in texts. Enter, for example df['text'], and get a list of clean text\n",
    "def cleaning(dfcolumn, stopwords_language):\n",
    "    \n",
    "    text_list_zero = dfcolumn.tolist()\n",
    "    \n",
    "    print ' '\n",
    "    print ' '\n",
    "    print 'eliminating excess of blank space: '\n",
    "    print ' '\n",
    "    \n",
    "    text_list_one = []\n",
    "    time1 = time.time()\n",
    "    for k in xrange(0, len(text_list_zero)): #tamanho da coluna \n",
    "        test = k % 100\n",
    "        if test == 0:\n",
    "            print k\n",
    "            \n",
    "        text_list_one.append( ' '.join(text_list_zero[k].split()) )\n",
    "        \n",
    "    print 'step time: ', time.time() - time1\n",
    "    print 'partial total time: ', time.time() - time1    \n",
    "    print ' '\n",
    "    print ' '\n",
    "\n",
    "    print ' '\n",
    "    print ' '\n",
    "    print 'eliminating urls: '\n",
    "    print ' '\n",
    "    \n",
    "    text_list_2 = []\n",
    "    time2 = time.time()\n",
    "    for k in xrange(0, len(text_list_one)):\n",
    "        test = k % 100\n",
    "        if test == 0:\n",
    "            print k\n",
    "        text = text_list_one[k]\n",
    "        text_clean = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', text)\n",
    "        text_list_2.append(text_clean) #remove a url do texto do tweet\n",
    "    print 'step time: ', time.time() - time2\n",
    "    print 'partial total time: ', time.time() - time1\n",
    "    print ' '\n",
    "    print ' '\n",
    "    \n",
    "    #text_list_2 é a lista com os tweets já sem a url\n",
    "    # strings to erase:\n",
    "    \n",
    "    toerase =  ['gostei de um video @youtube',\\\n",
    "                'www.','.com','.',',','!','?',';','@','...','/','(',')','\"',':',\\\n",
    "               '=','#','-','&','|','%','*','\"',\"'s\",'[', ']',\" ' \",\"$\", '\\n', '>', '<', '+',\\\n",
    "               'rss', '{', '}',\n",
    "               'website', 'https:','https', 'http', 'http:', \"'\", 'feedly', 'sign', 'comment', \\\n",
    "               'clique aqui', 'click here', 'comments']\n",
    "\n",
    "    \n",
    "    print ' '\n",
    "    print ' '\n",
    "    print 'eliminating more strings... '\n",
    "    print ' '    \n",
    "    \n",
    "    \n",
    "    text_list_3 = []\n",
    "    time3 = time.time()\n",
    "    for k in xrange(0, len(text_list_2)):\n",
    "        test = k % 100\n",
    "        if test == 0:\n",
    "            print k        \n",
    "        #text_zero = unidecode(text_list_2[k].decode('utf-8')).lower() #codifica a lista dos tweets em utf8\n",
    "        text_zero = unidecode((text_list_2[k].encode('utf-8')).decode('utf-8')).lower()\n",
    "        \n",
    "        vector_text = []\n",
    "        temp = text_zero #agora temp é a lista dos tweets em utf8\n",
    "        for j in xrange(0, len(toerase)):    \n",
    "            temp2 = temp.replace(toerase[j],' ') #substitui os caracteres to erase por espaços na lista já sem a url, \n",
    "            #remove um caracter indesejado por iteração de todos os tweets\n",
    "            #então na última iteração de j, todos os caracteres já estarão removidos\n",
    "            #por isso que pega o último elemento com índice -1 do vetor temp2\n",
    "            \n",
    "            vector_text.append(temp2) #vector_text já está ok \n",
    "            temp = vector_text[j] #agora temp recebe cada tweet \n",
    "        text_one = vector_text[-1].strip()    \n",
    "        tokens = [w for w in word_tokenize(text_one) if not w in stopwords.words(stopwords_language)]\n",
    "        #tokeniza cada tweet , então w é cada tweet tokenizado. Remove as stopwords dos tokens\n",
    "        #tokens contém os tweets já tokenizados e sem as stopwords \n",
    "       \n",
    "        text_final = ' '.join(tokens)\n",
    "        text_list_3.append(text_final)\n",
    "    print 'step time: ', time.time() - time3\n",
    "    print 'Total time: ', time.time() - time1\n",
    "    print ' '\n",
    "    print ' '\n",
    "    \n",
    "    return text_list_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder =  str(os.getcwd()+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframes\n",
    "df_temp_pos = pd.read_csv('data_pos_final.csv', sep = '\\t', encoding = 'utf-8')\n",
    "df_temp_neg = pd.read_csv('data_neg_final.csv', sep = '\\t', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatena os dataframes com as duas classes\n",
    "df_conc = [df_temp_pos, df_temp_neg]\n",
    "df_conc2 = pd.concat(df_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mistura as duas classes\n",
    "df_mix = df_conc2.sample(frac=1).reset_index(drop=True) #mix datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>traducao_pt</th>\n",
       "      <th>polaridade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble is , its filmmakers run out of cle...</td>\n",
       "      <td>o problema é que seus cineastas ficam sem idéi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's a feel-bad ending for a depressing story ...</td>\n",
       "      <td>é um final ruim para uma história deprimente q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chen films the resolutely downbeat smokers onl...</td>\n",
       "      <td>chen filma os fumantes decididamente pessimist...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  the trouble is , its filmmakers run out of cle...   \n",
       "1  it's a feel-bad ending for a depressing story ...   \n",
       "2  chen films the resolutely downbeat smokers onl...   \n",
       "\n",
       "                                         traducao_pt  polaridade  \n",
       "0  o problema é que seus cineastas ficam sem idéi...           0  \n",
       "1  é um final ruim para uma história deprimente q...           0  \n",
       "2  chen filma os fumantes decididamente pessimist...           0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mix[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "eliminating excess of blank space: \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  0.0549199581146\n",
      "partial total time:  0.0551919937134\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "eliminating urls: \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  0.0337610244751\n",
      "partial total time:  0.0891990661621\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "eliminating more strings... \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  26.4623718262\n",
      "Total time:  26.5517430305\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#limpa as colunas do dataset\n",
    "df_mix['review'] = cleaning(df_mix['review'], 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "eliminating excess of blank space: \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  0.0679531097412\n",
      "partial total time:  0.0682191848755\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "eliminating urls: \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  0.0374858379364\n",
      "partial total time:  0.10671210289\n",
      " \n",
      " \n",
      " \n",
      " \n",
      "eliminating more strings... \n",
      " \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "step time:  29.5804851055\n",
      "Total time:  29.6873910427\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "#limpa as colunas do dataset\n",
    "df_mix['traducao_pt'] = cleaning(df_mix['traducao_pt'], 'portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vetorização e conversão de variáveis\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "review = vectorizer.fit_transform(df_mix.review).toarray()\n",
    "traducao = vectorizer.fit_transform(df_mix.traducao_pt).toarray()\n",
    "polaridade = df_mix['polaridade'].as_matrix()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide a base em treino e teste com 70% para treino e 30% para teste\n",
    "#database do review\n",
    "x_train_review, x_test_review, y_train_review, y_test_review = train_test_split(review, polaridade, test_size=0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7296, 17490)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17490"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_review.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide a base em treino e teste com 70% para treino e 30% para teste\n",
    "#database da traducao\n",
    "x_train_trans, x_test_trans, y_train_trans, y_test_trans = train_test_split(traducao, polaridade, test_size=0.3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7296, 19196)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7296/7296 [==============================] - 2s 259us/step - loss: 0.6824 - acc: 0.5831\n",
      "Epoch 2/20\n",
      "7296/7296 [==============================] - 1s 194us/step - loss: 0.5719 - acc: 0.7578\n",
      "Epoch 3/20\n",
      "7296/7296 [==============================] - 1s 193us/step - loss: 0.4177 - acc: 0.8314\n",
      "Epoch 4/20\n",
      "7296/7296 [==============================] - 1s 196us/step - loss: 0.3078 - acc: 0.8795\n",
      "Epoch 5/20\n",
      "7296/7296 [==============================] - 1s 194us/step - loss: 0.2310 - acc: 0.9121\n",
      "Epoch 6/20\n",
      "7296/7296 [==============================] - 1s 191us/step - loss: 0.1809 - acc: 0.9334\n",
      "Epoch 7/20\n",
      "7296/7296 [==============================] - 1s 197us/step - loss: 0.1464 - acc: 0.9449\n",
      "Epoch 8/20\n",
      "7296/7296 [==============================] - 1s 193us/step - loss: 0.1104 - acc: 0.9626\n",
      "Epoch 9/20\n",
      "7296/7296 [==============================] - 2s 223us/step - loss: 0.0943 - acc: 0.9689\n",
      "Epoch 10/20\n",
      "7296/7296 [==============================] - 2s 308us/step - loss: 0.0718 - acc: 0.9753\n",
      "Epoch 11/20\n",
      "7296/7296 [==============================] - 2s 295us/step - loss: 0.0608 - acc: 0.9800\n",
      "Epoch 12/20\n",
      "7296/7296 [==============================] - 2s 289us/step - loss: 0.0530 - acc: 0.9823\n",
      "Epoch 13/20\n",
      "7296/7296 [==============================] - 2s 294us/step - loss: 0.0424 - acc: 0.9864\n",
      "Epoch 14/20\n",
      "7296/7296 [==============================] - 2s 291us/step - loss: 0.0373 - acc: 0.9885\n",
      "Epoch 15/20\n",
      "7296/7296 [==============================] - 2s 284us/step - loss: 0.0292 - acc: 0.9910\n",
      "Epoch 16/20\n",
      "7296/7296 [==============================] - 2s 286us/step - loss: 0.0269 - acc: 0.9916\n",
      "Epoch 17/20\n",
      "7296/7296 [==============================] - 2s 290us/step - loss: 0.0230 - acc: 0.9929\n",
      "Epoch 18/20\n",
      "7296/7296 [==============================] - 2s 289us/step - loss: 0.0208 - acc: 0.9941\n",
      "Epoch 19/20\n",
      "7296/7296 [==============================] - 2s 289us/step - loss: 0.0197 - acc: 0.9942\n",
      "Epoch 20/20\n",
      "7296/7296 [==============================] - 2s 287us/step - loss: 0.0157 - acc: 0.9953\n",
      "3128/3128 [==============================] - 1s 168us/step\n"
     ]
    }
   ],
   "source": [
    "#review data\n",
    "\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "dim = x_train_review.shape[1]\n",
    "model.add(Dense(64, input_dim=dim, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_review, y_train_review,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "acc_score_review = model.evaluate(x_test_review, y_test_review, batch_size=128)\n",
    "y_predicted_review = model.predict(x_test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7296/7296 [==============================] - 2s 306us/step - loss: 0.6816 - acc: 0.5829\n",
      "Epoch 2/20\n",
      "7296/7296 [==============================] - 2s 250us/step - loss: 0.5735 - acc: 0.7522\n",
      "Epoch 3/20\n",
      "7296/7296 [==============================] - 2s 252us/step - loss: 0.4202 - acc: 0.8320\n",
      "Epoch 4/20\n",
      "7296/7296 [==============================] - 2s 251us/step - loss: 0.3101 - acc: 0.8813\n",
      "Epoch 5/20\n",
      "7296/7296 [==============================] - 2s 243us/step - loss: 0.2324 - acc: 0.9124\n",
      "Epoch 6/20\n",
      "7296/7296 [==============================] - 2s 244us/step - loss: 0.1814 - acc: 0.9374\n",
      "Epoch 7/20\n",
      "7296/7296 [==============================] - 2s 243us/step - loss: 0.1463 - acc: 0.9496\n",
      "Epoch 8/20\n",
      "7296/7296 [==============================] - 2s 244us/step - loss: 0.1134 - acc: 0.9623\n",
      "Epoch 9/20\n",
      "7296/7296 [==============================] - 2s 246us/step - loss: 0.0938 - acc: 0.9675\n",
      "Epoch 10/20\n",
      "7296/7296 [==============================] - 2s 247us/step - loss: 0.0719 - acc: 0.9768\n",
      "Epoch 11/20\n",
      "7296/7296 [==============================] - 2s 245us/step - loss: 0.0621 - acc: 0.9801\n",
      "Epoch 12/20\n",
      "7296/7296 [==============================] - 2s 248us/step - loss: 0.0518 - acc: 0.9845\n",
      "Epoch 13/20\n",
      "7296/7296 [==============================] - 2s 254us/step - loss: 0.0395 - acc: 0.9896\n",
      "Epoch 14/20\n",
      "7296/7296 [==============================] - 2s 245us/step - loss: 0.0331 - acc: 0.9904\n",
      "Epoch 15/20\n",
      "7296/7296 [==============================] - 2s 249us/step - loss: 0.0286 - acc: 0.9905\n",
      "Epoch 16/20\n",
      "7296/7296 [==============================] - 2s 248us/step - loss: 0.0256 - acc: 0.9925\n",
      "Epoch 17/20\n",
      "7296/7296 [==============================] - 2s 259us/step - loss: 0.0238 - acc: 0.9923\n",
      "Epoch 18/20\n",
      "7296/7296 [==============================] - 2s 251us/step - loss: 0.0199 - acc: 0.9945\n",
      "Epoch 19/20\n",
      "7296/7296 [==============================] - 2s 254us/step - loss: 0.0172 - acc: 0.9953\n",
      "Epoch 20/20\n",
      "7296/7296 [==============================] - 2s 249us/step - loss: 0.0154 - acc: 0.9952\n",
      "3128/3128 [==============================] - 0s 158us/step\n"
     ]
    }
   ],
   "source": [
    "#translation data\n",
    "\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "dim = x_train_trans.shape[1]\n",
    "model.add(Dense(64, input_dim=dim, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_trans, y_train_trans,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "\n",
    "acc_score_trans = model.evaluate(x_test_trans, y_test_trans, batch_size=128)\n",
    "y_predicted_trans = model.predict(x_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6634988117096063, 0.747122761995896]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8011273779832493, 0.729539641943734]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3128, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_review_metrics = convertscore(y_predicted_review) \n",
    "y_predicted_trans_metrics = convertscore(y_predicted_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1100,  419],\n",
       "       [ 372, 1237]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix review\n",
    "#Thus in binary classification, the count of true negatives is C{0,0}, \n",
    "#false negatives is C{1,0}, true positives is C{1,1} and false positives is C{0,1}.\n",
    "\n",
    "cf_matrix_review = confusion_matrix(y_test_review, y_predicted_review_metrics)\n",
    "cf_matrix_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1062,  457],\n",
       "       [ 389, 1220]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix trans\n",
    "#Thus in binary classification, the count of true negatives is C{0,0}, \n",
    "#false negatives is C{1,0}, true positives is C{1,1} and false positives is C{0,1}.\n",
    "\n",
    "cf_matrix_trans = confusion_matrix(y_test_trans, y_predicted_trans_metrics)\n",
    "cf_matrix_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7466367453560272"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1 score review\n",
    "f1_score_review = f1_score(y_test_review, y_predicted_review_metrics, average='macro')  \n",
    "f1_score_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7288478208746012"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1 score trans\n",
    "f1_score_trans = f1_score(y_test_trans, y_predicted_trans_metrics, average='macro')  \n",
    "f1_score_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7471316425120773"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision score review\n",
    "#The precision is the ratio tp / (tp + fp)\n",
    "prec_score_review = precision_score(y_test_review, y_predicted_review_metrics, average='macro')  \n",
    "prec_score_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.729699296477621"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision score trans\n",
    "#The precision is the ratio tp / (tp + fp)\n",
    "#macro = binary classification\n",
    "prec_score_trans = precision_score(y_test_trans, y_predicted_trans_metrics, average='macro')  \n",
    "prec_score_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
